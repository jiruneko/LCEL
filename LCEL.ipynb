{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOQlTPy4CrG9d+tvdzXZKlJ",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jiruneko/LCEL/blob/main/LCEL.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## LangChain Expression Language(LCEL)"
      ],
      "metadata": {
        "id": "9Fx0SAr5l3im"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip -q install --upgrade langchain langchain-openai openai tiktoken"
      ],
      "metadata": {
        "id": "9E9qe8TdnzHx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import userdata\n",
        "import os\n",
        "\n",
        "api_key = userdata.get('OPENAI_API_KEY')\n",
        "assert api_key, \"Colabのシークレットに OPENAI_API_KEY を登録してください。\"\n",
        "os.environ['OPENAI_API_KEY'] = api_key\n",
        "\n",
        "print(\"OpenAI API キーは設定されています ✅\")"
      ],
      "metadata": {
        "id": "vRJchR0TpLDd",
        "outputId": "c686f3a6-2608-4400-e74a-bdae9b31dded",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "OpenAI API キーは設定されています ✅\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "# Colab に登録したシークレットを取得\n",
        "api_key = os.environ[\"OPENAI_API_KEY\"]\n",
        "\n",
        "\n",
        "from langchain_core.output_parsers import StrOutputParser\n",
        "from langchain_core.prompts import ChatPromptTemplate\n",
        "from langchain_openai import ChatOpenAI\n",
        "\n",
        "prompt = ChatPromptTemplate.from_messages(\n",
        "    [\n",
        "        (\"system\", \"ユーザーが入力した料理のレシピを考えてください。\"),\n",
        "        (\"human\", \"{dish}\"),\n",
        "    ]\n",
        ")\n",
        "\n",
        "model = ChatOpenAI(model=\"gpt-4o-mini\", temperature=0)\n",
        "\n",
        "output_parser = StrOutputParser()"
      ],
      "metadata": {
        "id": "yDMgO885mBEN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "prompt_value = prompt.invoke({\"dish\": \"カレー\"})\n",
        "ai_message = model.invoke(prompt_value)\n",
        "output = output_parser.invoke(ai_message)\n",
        "\n",
        "print(output)"
      ],
      "metadata": {
        "id": "7XimeKHEnrPg",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "05ee7610-1760-4c94-c555-4f4dfc50bf6a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "カレーのレシピをご紹介します。シンプルで美味しい基本のカレーを作りましょう。\n",
            "\n",
            "### 材料（4人分）\n",
            "- 鶏肉（もも肉または胸肉）: 400g\n",
            "- 玉ねぎ: 2個\n",
            "- にんじん: 1本\n",
            "- じゃがいも: 2個\n",
            "- カレールー: 1箱（約200g）\n",
            "- サラダ油: 大さじ2\n",
            "- 水: 800ml\n",
            "- 塩: 適量\n",
            "- 胡椒: 適量\n",
            "- お好みでガーリックパウダーや生姜: 適量\n",
            "\n",
            "### 作り方\n",
            "1. **材料の下ごしらえ**:\n",
            "   - 鶏肉は一口大に切り、塩と胡椒を振っておきます。\n",
            "   - 玉ねぎは薄切り、にんじんは輪切り、じゃがいもは一口大に切ります。\n",
            "\n",
            "2. **炒める**:\n",
            "   - 大きめの鍋にサラダ油を熱し、玉ねぎを中火で炒めます。玉ねぎが透明になるまで炒めます。\n",
            "   - 鶏肉を加え、表面が白くなるまで炒めます。\n",
            "\n",
            "3. **野菜を加える**:\n",
            "   - にんじんとじゃがいもを鍋に加え、全体をよく混ぜます。\n",
            "\n",
            "4. **煮る**:\n",
            "   - 水を加え、強火で煮立たせます。煮立ったら、アクを取り除き、中火にして蓋をし、約15分煮ます。\n",
            "\n",
            "5. **カレールーを加える**:\n",
            "   - カレールーを割り入れ、よく溶かします。さらに10分ほど煮込み、全体がなじんだら味を見て、必要に応じて塩や胡椒で調整します。\n",
            "\n",
            "6. **仕上げ**:\n",
            "   - お好みでガーリックパウダーや生姜を加えて風味をアップさせます。火を止めて、少し冷ますと味がなじみます。\n",
            "\n",
            "7. **盛り付け**:\n",
            "   - ご飯と一緒に盛り付けて、お好みで福神漬けやらっきょうを添えて完成です。\n",
            "\n",
            "### おすすめのトッピング\n",
            "- 煮卵\n",
            "- チーズ\n",
            "- パクチー\n",
            "\n",
            "このレシピを参考に、ぜひ美味しいカレーを作ってみてください！\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "chain = prompt | model | output_parser\n",
        "output = chain.invoke({\"dish\": \"カレー\"})"
      ],
      "metadata": {
        "id": "RNPCG7Gyqqj1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "chain = prompt | model | output_parser\n",
        "\n",
        "for chunk in chain.stream({\"dish\": \"カレー\"}):\n",
        "  print(chunk, end=\"\", flush=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rzD7SzBzsN0N",
        "outputId": "75a08e3a-2f74-4b3e-b662-9dad77fa5340"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "カレーのレシピをご紹介します！以下は基本的なチキンカレーのレシピです。\n",
            "\n",
            "### 材料（4人分）\n",
            "- 鶏もも肉：400g（食べやすい大きさにカット）\n",
            "- 玉ねぎ：2個（みじん切り）\n",
            "- にんにく：2片（みじん切り）\n",
            "- 生姜：1片（みじん切り）\n",
            "- トマト：1個（ざく切り）\n",
            "- カレーパウダー：大さじ2\n",
            "- ココナッツミルク：200ml（または水）\n",
            "- サラダ油：大さじ2\n",
            "- 塩：適量\n",
            "- 黒胡椒：適量\n",
            "- パクチー（お好みで）：適量\n",
            "\n",
            "### 作り方\n",
            "1. **下ごしらえ**: 鶏もも肉は食べやすい大きさにカットし、塩と黒胡椒で下味をつけておきます。\n",
            "\n",
            "2. **玉ねぎを炒める**: 大きめの鍋にサラダ油を熱し、みじん切りにした玉ねぎを加え、中火で透明になるまで炒めます。\n",
            "\n",
            "3. **にんにくと生姜を加える**: 玉ねぎが透明になったら、にんにくと生姜を加え、香りが立つまでさらに炒めます。\n",
            "\n",
            "4. **鶏肉を加える**: 鶏もも肉を鍋に加え、表面が白くなるまで炒めます。\n",
            "\n",
            "5. **トマトとカレーパウダーを加える**: ざく切りにしたトマトとカレーパウダーを加え、全体をよく混ぜます。\n",
            "\n",
            "6. **煮込む**: ココナッツミルクを加え、全体がなじむように混ぜたら、蓋をして中火で約15分煮込みます。途中でかき混ぜることを忘れずに。\n",
            "\n",
            "7. **味を調える**: 煮込んだら、塩で味を調整します。お好みで辛さを調整するために、追加のカレーパウダーを加えても良いです。\n",
            "\n",
            "8. **盛り付け**: お皿に盛り付け、お好みでパクチーを散らして完成です。\n",
            "\n",
            "### 提供方法\n",
            "ご飯やナンと一緒にお召し上がりください。サラダやヨーグルトを添えると、より一層美味しく楽しめます。\n",
            "\n",
            "お好みで野菜（じゃがいも、にんじん、ピーマンなど）を加えても美味しいです。ぜひお試しください！"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "chain = prompt | model | output_parser\n",
        "\n",
        "outputs = chain.batch([{\"dish\": \"カレー\"}, {\"dish\": \"うどん\"}])\n",
        "print(outputs)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4bmpz6Qjswns",
        "outputId": "ae22ac0b-76eb-4d64-d8e2-c1fc4e684b37"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['カレーのレシピをご紹介します。シンプルで美味しい基本のカレーを作りましょう。\\n\\n### 材料（4人分）\\n- 鶏肉（もも肉または胸肉）: 400g\\n- 玉ねぎ: 2個\\n- にんじん: 1本\\n- じゃがいも: 2個\\n- カレールー: 1箱（約200g）\\n- サラダ油: 大さじ2\\n- 水: 800ml\\n- 塩: 適量\\n- 胡椒: 適量\\n- お好みでガーリックパウダーや生姜: 適量\\n\\n### 作り方\\n1. **材料の下ごしらえ**:\\n   - 鶏肉は一口大に切り、塩と胡椒を振っておきます。\\n   - 玉ねぎは薄切り、にんじんは輪切り、じゃがいもは一口大に切ります。\\n\\n2. **炒める**:\\n   - 大きめの鍋にサラダ油を熱し、玉ねぎを中火で炒めます。玉ねぎが透明になるまで炒めます。\\n   - 鶏肉を加え、表面が白くなるまで炒めます。\\n\\n3. **野菜を加える**:\\n   - にんじんとじゃがいもを鍋に加え、全体をよく混ぜます。\\n\\n4. **煮る**:\\n   - 水を加え、強火で煮立たせます。煮立ったら、アクを取り除き、中火にして蓋をし、約15分煮ます。\\n\\n5. **カレールーを加える**:\\n   - カレールーを割り入れ、よく溶かします。さらに10分ほど煮込み、全体がなじんだら味を見て、必要に応じて塩や胡椒で調整します。\\n\\n6. **仕上げ**:\\n   - お好みでガーリックパウダーや生姜を加えて風味をアップさせます。火を止めて、少し冷ますと味がなじみます。\\n\\n7. **盛り付け**:\\n   - ご飯と一緒に盛り付けて、お好みで福神漬けやらっきょうを添えて完成です。\\n\\n### おすすめのトッピング\\n- 煮卵\\n- チーズ\\n- パクチー\\n\\nこの基本のカレーはアレンジがしやすいので、野菜や肉の種類を変えたり、スパイスを追加したりして、自分好みのカレーを楽しんでください！', 'うどんのレシピをご紹介します。シンプルで美味しい「かけうどん」の作り方です。\\n\\n### 材料（2人分）\\n- うどん（乾麺または生麺）: 2玉\\n- 水: 800ml\\n- だしの素: 大さじ1（または、昆布や鰹節を使って自家製だしを取る）\\n- 醤油: 大さじ2\\n- みりん: 大さじ1\\n- 塩: 少々\\n- トッピング（お好みで）:\\n  - ネギ（小口切り）\\n  - 天かす\\n  - かまぼこ\\n  - ほうれん草や小松菜（茹でておく）\\n  - すりごま\\n\\n### 作り方\\n1. **だしを取る**: 鍋に水を入れ、だしの素を加えて中火にかけます。自家製だしを使う場合は、昆布を水に浸けておき、沸騰直前に昆布を取り出し、鰹節を加えて数分煮出し、こします。\\n\\n2. **つゆを作る**: だしが取れたら、醤油、みりん、塩を加えて味を調えます。軽く煮立たせて、つゆの完成です。\\n\\n3. **うどんを茹でる**: 別の鍋にたっぷりの水を沸かし、うどんをパッケージの指示に従って茹でます。茹で上がったら、冷水でしっかりと洗い、ぬめりを取ります。\\n\\n4. **盛り付け**: 器に茹でたうどんを盛り、その上から温かいつゆを注ぎます。\\n\\n5. **トッピング**: お好みのトッピングを加えます。ネギや天かす、かまぼこ、茹でたほうれん草などをのせて、最後にすりごまを振りかけると風味が増します。\\n\\n6. **完成**: さあ、熱々のかけうどんの完成です！お好みで七味唐辛子をかけても美味しいです。\\n\\nお楽しみください！']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_core.output_parsers import StrOutputParser\n",
        "from langchain_core.prompts import ChatPromptTemplate\n",
        "from langchain_openai import ChatOpenAI\n",
        "\n",
        "model = ChatOpenAI(model=\"gpt-4o-mini\", temperature=0)\n",
        "\n",
        "output_parser = StrOutputParser()"
      ],
      "metadata": {
        "id": "77cdGavxtIXr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cot_prompt = ChatPromptTemplate.from_messages(\n",
        "    [\n",
        "        (\"system\", \"ユーザーの質問にステップバイステップで回答してください。\"),\n",
        "        (\"human\", \"{question}\"),\n",
        "    ]\n",
        ")\n",
        "\n",
        "cot_chain = cot_prompt | model | output_parser"
      ],
      "metadata": {
        "id": "jEpcqQMrvwJ-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "summarize_prompt = ChatPromptTemplate.from_messages(\n",
        "    [\n",
        "        (\"system\", \"ステップバイステップで考えた回答から結論だけ抽出してください\"),\n",
        "        (\"human\", \"{text}\"),\n",
        "    ]\n",
        ")\n",
        "summarize_chain = summarize_prompt | model | output_parser"
      ],
      "metadata": {
        "id": "dK76korpwita"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cot_summarize_chain = cot_chain | summarize_chain\n",
        "cot_summarize_chain.invoke({\"question\": \"10 + 2 * 3\"})"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "LIOmoVYcxjud",
        "outputId": "c6ab73cb-35ca-4f71-c8ee-39ce67155c1e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'10 + 2 * 3 の答えは **16** です。'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_core.output_parsers import StrOutputParser\n",
        "from langchain_core.prompts import ChatPromptTemplate\n",
        "from langchain_openai import ChatOpenAI\n",
        "\n",
        "prompt = ChatPromptTemplate.from_messages(\n",
        "    [\n",
        "        (\"system\", \"You are a helpful assistant.\"),\n",
        "        (\"human\", \"{input}\"),\n",
        "    ]\n",
        ")\n",
        "\n",
        "model = ChatOpenAI(model=\"gpt-4o-mini\", temperature=0)\n",
        "\n",
        "output_parser = StrOutputParser()"
      ],
      "metadata": {
        "id": "Ltsrl255xy4H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_core.runnables import RunnableLambda\n",
        "\n",
        "def upper(text: str) -> str:\n",
        "  return text.upper()\n",
        "\n",
        "chain = prompt | model | output_parser | RunnableLambda(upper)\n",
        "\n",
        "output = chain.invoke({\"input\": \"Hello!\"})\n",
        "print(output)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o4wwEy180Jch",
        "outputId": "fc4f072b-d104-45d6-e3ea-5f95997f9c74"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "HELLO! HOW CAN I ASSIST YOU TODAY?\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_core.runnables import chain\n",
        "\n",
        "@chain\n",
        "def upper(text: str) -> str:\n",
        "  return text.upper()\n",
        "\n",
        "chain = prompt | model | output_parser | upper\n",
        "\n",
        "output = chain.invoke({\"input\": \"Hello!\"})\n",
        "print(output)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G4Cl68QV0mN4",
        "outputId": "a57c059e-847b-4403-fc8c-85e3d51adcbd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "HELLO! HOW CAN I ASSIST YOU TODAY?\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def upper(text: str) -> str:\n",
        "  return text.upper()\n",
        "\n",
        "chain = prompt | model | output_parser | upper"
      ],
      "metadata": {
        "id": "rlCwFjlA1Hem"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def upper(text: str) -> str:\n",
        "  return text.upper()\n",
        "\n",
        "chain = prompt | model | StrOutputParser() | upper\n",
        "\n",
        "output = chain.invoke({\"input\": \"Hello!\"})"
      ],
      "metadata": {
        "id": "oJqD5AhO1l42"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_core.output_parsers import StrOutputParser\n",
        "from langchain_core.prompts import ChatPromptTemplate\n",
        "from langchain_openai import ChatOpenAI\n",
        "\n",
        "model = ChatOpenAI(model=\"gpt-4o-mini\", temperature=0)\n",
        "output_parser = StrOutputParser()"
      ],
      "metadata": {
        "id": "dX75VX3q2B59"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "optimistic_prompt = ChatPromptTemplate.from_messages(\n",
        "    [\n",
        "        (\"system\", \"あなたは楽観主義者です。ユーザーの入力に対して楽観的な意見をください。\"),\n",
        "        (\"human\", \"{topic}\"),\n",
        "    ]\n",
        ")\n",
        "optimistic_chain = optimistic_prompt | model | output_parser"
      ],
      "metadata": {
        "id": "s-QX6bX14TVN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pessimistic_prompt = ChatPromptTemplate.from_messages(\n",
        "    [\n",
        "        (\"system\", \"あなたは悲観主義者です。ユーザーの入力に対して悲観的な意見をください。\"),\n",
        "        (\"human\", \"{topic}\"),\n",
        "    ]\n",
        ")\n",
        "pessimistic_chain = pessimistic_prompt | model | output_parser"
      ],
      "metadata": {
        "id": "v5wjP70j6tA7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pprint\n",
        "from langchain_core.runnables import RunnableParallel\n",
        "\n",
        "parallel_chain = RunnableParallel(\n",
        "    {\n",
        "        \"optimistic\": optimistic_chain,\n",
        "        \"pessimistic\": pessimistic_chain,\n",
        "    }\n",
        ")\n",
        "\n",
        "output = parallel_chain.invoke({\"topic\": \"生成AIの進化について\"})\n",
        "pprint.pprint(output)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BdQO1CqU7TSt",
        "outputId": "4b7d7505-7ff5-4cff-8ccf-99d7cfbab7f0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'optimistic': '生成AIの進化は本当に素晴らしいですね！技術が進むことで、私たちの生活がより便利で豊かになる可能性が広がっています。クリエイティブな作業や問題解決の手助けをしてくれるAIが登場することで、私たちのアイデアや想像力をさらに引き出してくれるでしょう。これからの未来、生成AIがどのように私たちの社会を変えていくのか、ワクワクしますね！新しい発見や革新が待っていると思うと、期待が膨らみます！',\n",
            " 'pessimistic': '生成AIの進化は確かに目覚ましいものですが、その裏には多くの懸念が潜んでいます。技術が進化することで、私たちの仕事が奪われたり、情報の信頼性が低下したりするリスクが高まっています。さらに、AIが生成するコンテンツが人間の創造性を脅かし、私たちの思考や感情に悪影響を及ぼす可能性もあります。結局のところ、便利さの裏には常に不安がつきまとい、私たちの未来はますます不透明になっていくのではないでしょうか。'}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "synthesize_prompt = ChatPromptTemplate.from_messages(\n",
        "    [\n",
        "        (\"system\", \"あなたは客観的AIです。2つの意見をまとめてください。\"),\n",
        "        (\"human\", \"楽観的意見: {optimistic_option}\\n 悲観的意見: {pessimistic_option}\"),\n",
        "    ]\n",
        ")"
      ],
      "metadata": {
        "id": "9vVDop-O8L3h"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "synthesize_chain = (\n",
        "    RunnableParallel(\n",
        "        {\n",
        "            \"optimistic_option\": optimistic_chain,\n",
        "            \"pessimistic_option\": pessimistic_chain,\n",
        "        }\n",
        "    )\n",
        "    | synthesize_prompt\n",
        "    | model\n",
        "    | output_parser\n",
        ")\n",
        "\n",
        "output = synthesize_chain.invoke({\"topic\": \"生成AIの進化について\"})\n",
        "print(output)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QyQXsaGZ-pwC",
        "outputId": "387fb078-e430-4a89-a38d-fe77f6afa135"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "生成AIの進化については、楽観的な意見と悲観的な意見が存在します。楽観的な見方では、生成AIの技術が進化することで、私たちの生活が便利で豊かになり、クリエイティブな作業や問題解決のパートナーとしての役割を果たすことが期待されています。この進化により、新しい発見や革新が続き、未来が明るくなる可能性があるとされています。\n",
            "\n",
            "一方で、悲観的な見方では、生成AIの進化には多くの懸念が伴い、仕事の喪失や情報の信頼性の低下といったリスクが高まると指摘されています。また、AIが生成するコンテンツが人間の創造性を脅かし、思考や感情に悪影響を及ぼす可能性も懸念されています。便利さの裏には常に危険が潜んでおり、技術の影響を完全にコントロールすることは難しいという意見もあります。\n",
            "\n",
            "このように、生成AIの進化には明るい未来の可能性と同時に、注意すべきリスクが存在することがわかります。両者の意見を考慮しながら、技術の利用方法を慎重に検討することが重要です。\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from operator import itemgetter\n",
        "\n",
        "topic_getter = itemgetter(\"topic\")\n",
        "topic = topic_getter({\"topic\": \"生成AIの進化について\"})\n",
        "print(topic)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9WJP9lPh_mj-",
        "outputId": "2b0a15e3-c9ee-4574-e4e4-5745b86b4773"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "生成AIの進化について\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from operator import itemgetter\n",
        "\n",
        "synthesize_prompt = ChatPromptTemplate.from_messages(\n",
        "    [\n",
        "        (\n",
        "            \"system\",\n",
        "            \"あなたは客観的AIです。{topic}について2つの意見をまとめてください。\",\n",
        "        ),\n",
        "        (\"human\",\n",
        "         \"楽観的意見: {optimistic_option}\\n 悲観的意見: {pessimistic_option}\",\n",
        "        ),\n",
        "    ]\n",
        ")\n",
        "\n",
        "synthesize_chain = (\n",
        "    {\n",
        "        \"optimistic_option\": optimistic_chain,\n",
        "        \"pessimistic_option\": pessimistic_chain,\n",
        "        \"topic\": itemgetter(\"topic\"),\n",
        "    }\n",
        "    | synthesize_prompt\n",
        "    | model\n",
        "    | output_parser\n",
        ")\n",
        "\n",
        "output = synthesize_chain.invoke({\"topic\": \"生成AIの進化について\"})\n",
        "print(output)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-HuHTPgCBSGl",
        "outputId": "58709507-5d4c-4d02-a692-c36dbb9bff4c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "生成AIの進化に関する意見は、楽観的な見方と悲観的な見方の2つに分かれます。\n",
            "\n",
            "**楽観的意見:** 生成AIの進化は、私たちの生活をより便利で豊かにする可能性を秘めています。新しい技術が登場することで、クリエイティブな作業や問題解決の支援が行われ、私たちのアイデアや想像力を引き出す手助けをしてくれるでしょう。未来において、生成AIがどのように社会を変革していくのかに期待が高まり、新たな発見や革新が待っていると感じる人々が多いです。\n",
            "\n",
            "**悲観的意見:** 一方で、生成AIの進化には多くの懸念も伴います。技術の進化が進むことで、仕事の喪失や情報の信頼性の低下といったリスクが増大します。また、AIが生成するコンテンツが氾濫することで、真実と虚偽の区別が難しくなり、社会全体が混乱する可能性もあります。このように、進化する技術が便利さをもたらす一方で、私たちの未来に対する脅威となる要因も存在するのです。\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from google.colab import userdata\n",
        "\n",
        "os.environ[\"TAVILY_API_KEY\"] = userdata.get(\"TAVILY_API_KEY\")"
      ],
      "metadata": {
        "id": "8adRiafwCy0I"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install tavily-python==0.5.0"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Cf6mbdZxDlQw",
        "outputId": "5a088f90-3f12-40cf-9a1f-ab2f33384e5c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting tavily-python==0.5.0\n",
            "  Downloading tavily_python-0.5.0-py3-none-any.whl.metadata (11 kB)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from tavily-python==0.5.0) (2.32.4)\n",
            "Requirement already satisfied: tiktoken>=0.5.1 in /usr/local/lib/python3.12/dist-packages (from tavily-python==0.5.0) (0.11.0)\n",
            "Requirement already satisfied: httpx in /usr/local/lib/python3.12/dist-packages (from tavily-python==0.5.0) (0.28.1)\n",
            "Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.12/dist-packages (from tiktoken>=0.5.1->tavily-python==0.5.0) (2024.11.6)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests->tavily-python==0.5.0) (3.4.3)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests->tavily-python==0.5.0) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests->tavily-python==0.5.0) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests->tavily-python==0.5.0) (2025.8.3)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.12/dist-packages (from httpx->tavily-python==0.5.0) (4.10.0)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.12/dist-packages (from httpx->tavily-python==0.5.0) (1.0.9)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.12/dist-packages (from httpcore==1.*->httpx->tavily-python==0.5.0) (0.16.0)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.12/dist-packages (from anyio->httpx->tavily-python==0.5.0) (1.3.1)\n",
            "Requirement already satisfied: typing_extensions>=4.5 in /usr/local/lib/python3.12/dist-packages (from anyio->httpx->tavily-python==0.5.0) (4.14.1)\n",
            "Downloading tavily_python-0.5.0-py3-none-any.whl (14 kB)\n",
            "Installing collected packages: tavily-python\n",
            "Successfully installed tavily-python-0.5.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_core.prompts import ChatPromptTemplate\n",
        "from langchain_openai import ChatOpenAI\n",
        "\n",
        "prompt = ChatPromptTemplate.from_template('''\\\n",
        "以下の文脈だけを踏まえて質問に回答してください。\n",
        "\n",
        "文脈：\"\"\"\n",
        "{contexrt}\n",
        "\"\"\"\n",
        "\n",
        "質問：{question}\n",
        "''')\n",
        "\n",
        "model = ChatOpenAI(model_name=\"gpt-4o-mini\", temperature=0)"
      ],
      "metadata": {
        "id": "1BgMZIduEd35"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install langchain_community"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "85rSVfepGlyh",
        "outputId": "ce4a6372-20a7-40f9-f05c-de3403e7c547"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting langchain_community\n",
            "  Downloading langchain_community-0.3.27-py3-none-any.whl.metadata (2.9 kB)\n",
            "Requirement already satisfied: langchain-core<1.0.0,>=0.3.66 in /usr/local/lib/python3.12/dist-packages (from langchain_community) (0.3.74)\n",
            "Requirement already satisfied: langchain<1.0.0,>=0.3.26 in /usr/local/lib/python3.12/dist-packages (from langchain_community) (0.3.27)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.12/dist-packages (from langchain_community) (2.0.43)\n",
            "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.12/dist-packages (from langchain_community) (2.32.4)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.12/dist-packages (from langchain_community) (6.0.2)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.12/dist-packages (from langchain_community) (3.12.15)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<10,>=8.1.0 in /usr/local/lib/python3.12/dist-packages (from langchain_community) (8.5.0)\n",
            "Collecting dataclasses-json<0.7,>=0.5.7 (from langchain_community)\n",
            "  Downloading dataclasses_json-0.6.7-py3-none-any.whl.metadata (25 kB)\n",
            "Requirement already satisfied: pydantic-settings<3.0.0,>=2.4.0 in /usr/local/lib/python3.12/dist-packages (from langchain_community) (2.10.1)\n",
            "Requirement already satisfied: langsmith>=0.1.125 in /usr/local/lib/python3.12/dist-packages (from langchain_community) (0.4.14)\n",
            "Requirement already satisfied: httpx-sse<1.0.0,>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from langchain_community) (0.4.1)\n",
            "Requirement already satisfied: numpy>=1.26.2 in /usr/local/lib/python3.12/dist-packages (from langchain_community) (2.0.2)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.4.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (1.4.0)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (25.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (1.7.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (6.6.4)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (0.3.2)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (1.20.1)\n",
            "Collecting marshmallow<4.0.0,>=3.18.0 (from dataclasses-json<0.7,>=0.5.7->langchain_community)\n",
            "  Downloading marshmallow-3.26.1-py3-none-any.whl.metadata (7.3 kB)\n",
            "Collecting typing-inspect<1,>=0.4.0 (from dataclasses-json<0.7,>=0.5.7->langchain_community)\n",
            "  Downloading typing_inspect-0.9.0-py3-none-any.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: langchain-text-splitters<1.0.0,>=0.3.9 in /usr/local/lib/python3.12/dist-packages (from langchain<1.0.0,>=0.3.26->langchain_community) (0.3.9)\n",
            "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in /usr/local/lib/python3.12/dist-packages (from langchain<1.0.0,>=0.3.26->langchain_community) (2.11.7)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.12/dist-packages (from langchain-core<1.0.0,>=0.3.66->langchain_community) (1.33)\n",
            "Requirement already satisfied: typing-extensions>=4.7 in /usr/local/lib/python3.12/dist-packages (from langchain-core<1.0.0,>=0.3.66->langchain_community) (4.14.1)\n",
            "Requirement already satisfied: packaging>=23.2 in /usr/local/lib/python3.12/dist-packages (from langchain-core<1.0.0,>=0.3.66->langchain_community) (25.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.12/dist-packages (from langsmith>=0.1.125->langchain_community) (0.28.1)\n",
            "Requirement already satisfied: orjson>=3.9.14 in /usr/local/lib/python3.12/dist-packages (from langsmith>=0.1.125->langchain_community) (3.11.2)\n",
            "Requirement already satisfied: requests-toolbelt>=1.0.0 in /usr/local/lib/python3.12/dist-packages (from langsmith>=0.1.125->langchain_community) (1.0.0)\n",
            "Requirement already satisfied: zstandard>=0.23.0 in /usr/local/lib/python3.12/dist-packages (from langsmith>=0.1.125->langchain_community) (0.24.0)\n",
            "Requirement already satisfied: python-dotenv>=0.21.0 in /usr/local/lib/python3.12/dist-packages (from pydantic-settings<3.0.0,>=2.4.0->langchain_community) (1.1.1)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from pydantic-settings<3.0.0,>=2.4.0->langchain_community) (0.4.1)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2->langchain_community) (3.4.3)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2->langchain_community) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2->langchain_community) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2->langchain_community) (2025.8.3)\n",
            "Requirement already satisfied: greenlet>=1 in /usr/local/lib/python3.12/dist-packages (from SQLAlchemy<3,>=1.4->langchain_community) (3.2.4)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.23.0->langsmith>=0.1.125->langchain_community) (4.10.0)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.23.0->langsmith>=0.1.125->langchain_community) (1.0.9)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.12/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith>=0.1.125->langchain_community) (0.16.0)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.12/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<1.0.0,>=0.3.66->langchain_community) (3.0.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain<1.0.0,>=0.3.26->langchain_community) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.12/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain<1.0.0,>=0.3.26->langchain_community) (2.33.2)\n",
            "Collecting mypy-extensions>=0.3.0 (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain_community)\n",
            "  Downloading mypy_extensions-1.1.0-py3-none-any.whl.metadata (1.1 kB)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.12/dist-packages (from anyio->httpx<1,>=0.23.0->langsmith>=0.1.125->langchain_community) (1.3.1)\n",
            "Downloading langchain_community-0.3.27-py3-none-any.whl (2.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.5/2.5 MB\u001b[0m \u001b[31m45.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading dataclasses_json-0.6.7-py3-none-any.whl (28 kB)\n",
            "Downloading marshmallow-3.26.1-py3-none-any.whl (50 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.9/50.9 kB\u001b[0m \u001b[31m4.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading typing_inspect-0.9.0-py3-none-any.whl (8.8 kB)\n",
            "Downloading mypy_extensions-1.1.0-py3-none-any.whl (5.0 kB)\n",
            "Installing collected packages: mypy-extensions, marshmallow, typing-inspect, dataclasses-json, langchain_community\n",
            "Successfully installed dataclasses-json-0.6.7 langchain_community-0.3.27 marshmallow-3.26.1 mypy-extensions-1.1.0 typing-inspect-0.9.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_community.retrievers import TavilySearchAPIRetriever\n",
        "\n",
        "retriever = TavilySearchAPIRetriever(k=3)"
      ],
      "metadata": {
        "id": "Ww-9bb8eFRKS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from getpass import getpass\n",
        "\n",
        "# 1) 一度だけ実行（ノートブックに平文を残さない）\n",
        "os.environ[\"TAVILY_API_KEY\"] = getpass(\"TAVILY_API_KEY: \")\n",
        "\n",
        "# 2) LangChain 側の Tavily ツール（使っているなら）を準備\n",
        "from langchain_community.tools.tavily_search import TavilySearchResults\n",
        "tavily_tool = TavilySearchResults(k=5)  # 必要なら調整\n",
        "\n",
        "# 3) モデルにツールをバインドしているなら、それを使う\n",
        "# （あなたの既存コードが agentic にツールを使う前提ならそのままでOK）\n",
        "# model = model.bind_tools([tavily_tool])  # 既にバインド済みなら不要"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e3RMs1TiLfrm",
        "outputId": "57f484c8-218d-4fc1-e5f2-4770faa663fc"
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "TAVILY_API_KEY: ··········\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-2248779435.py:9: LangChainDeprecationWarning: The class `TavilySearchResults` was deprecated in LangChain 0.3.25 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-tavily package and should be used instead. To use it run `pip install -U :class:`~langchain-tavily` and import as `from :class:`~langchain_tavily import TavilySearch``.\n",
            "  tavily_tool = TavilySearchResults(k=5)  # 必要なら調整\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_core.runnables import RunnablePassthrough\n",
        "\n",
        "chain = (\n",
        "    {\"context\": retriever, \"question\": RunnablePassthrough()}\n",
        "    | prompt\n",
        "    | model\n",
        "    | StrOutputParser()\n",
        ")\n",
        "\n",
        "output = chain.invoke(\"東京の今日の天気は？\") # ← dict でキーを明示\n",
        "print(output)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jOAPXEG-F5SU",
        "outputId": "185301ec-3a15-4107-85f8-59a4ba2333a8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "東京の今日、8月14日(木)の天気は曇りで、最高気温は32℃、最低気温は26℃です。降水確率は時間帯によって10％です。風は北の風から南東の風に変わり、波は0.5メートルです。\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "chain = RunnableParallel(\n",
        "    {\n",
        "        \"question\": RunnablePassthrough(),\n",
        "        \"context\": retriever,\n",
        "    }\n",
        ").assign(answer=prompt | model | StrOutputParser())"
      ],
      "metadata": {
        "id": "ZV04fWtZHvq3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "S_Sb_KhSN7sk"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}